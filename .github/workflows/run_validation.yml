name: Validate Rule Contributions

on:
  pull_request:
    paths:
      - 'rules/**'
    types: [opened, synchronize, reopened]

jobs:
  validate-rules:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      issues: write
      pull-requests: write
    
    steps:
      - name: Checkout PR
        uses: actions/checkout@v4
        with:
          submodules: recursive
          fetch-depth: 0
      
      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      
      - name: Setup Virtual Environment
        run: python -m venv venv

      - name: Initialize engine submodule and Install Dependencies
        run: |
          VENV_PYTHON=$(pwd)/venv/bin/python
          VENV_PIP=$(pwd)/venv/bin/pip
          
          $VENV_PYTHON -m pip install --upgrade pip
          
          git submodule update --init --recursive
          
          cd engine
          $VENV_PIP install -r requirements.txt
          $VENV_PIP install -r requirements-dev.txt
          
          SUBMODULE_COMMIT=$(git rev-parse HEAD)
          echo "Using engine submodule at commit: $SUBMODULE_COMMIT"
          cd ..

      - name: Detect changed rules
        id: changed-rules
        run: |
          # Get list of changed rule directories
          CHANGED_RULES=$(git diff --name-only origin/${{ github.base_ref }}...HEAD | grep '^rules/CG' | cut -d'/' -f2 | sort -u)
          
          if [ -z "$CHANGED_RULES" ]; then
            echo "No rule changes detected"
            echo "rules=" >> $GITHUB_OUTPUT
          else
            echo "Changed rules: $CHANGED_RULES"
            # Convert to JSON array
            RULES_JSON=$(echo "$CHANGED_RULES" | jq -R -s -c 'split("\n") | map(select(length > 0))')
            echo "rules=$RULES_JSON" >> $GITHUB_OUTPUT
          fi

      - name: Validate changed rules
        if: steps.changed-rules.outputs.rules != ''
        id: validate
        continue-on-error: true
        run: |
          # Define the python path at the TOP of this step so it's easy to reuse
          PYTHON_CMD="./venv/bin/python"
          
          RULES='${{ steps.changed-rules.outputs.rules }}'
          
          # Initialize report file
          REPORT_FILE="validation_report.md"
          echo "# Rule Validation Report" > $REPORT_FILE
          echo "" >> $REPORT_FILE
          echo "**Commit:** \`${{ github.event.pull_request.head.sha }}\`" >> $REPORT_FILE
          echo "" >> $REPORT_FILE
          
          OVERALL_SUCCESS=true
          
          echo "$RULES" | jq -r '.[]' | while read -r RULE_ID; do
            echo ""
            echo "Validating $RULE_ID"
            echo "## Rule: $RULE_ID" >> $REPORT_FILE
            echo "" >> $REPORT_FILE

            YML_COUNT=$(find "rules/$RULE_ID" -maxdepth 1 -name "*.yml" | wc -l)
            if [ "$YML_COUNT" -eq 0 ]; then
              echo "ERROR: No YAML file found in rules/$RULE_ID/"
              echo "**ERROR:** No YAML file found in rules/$RULE_ID/" >> $REPORT_FILE
              echo "" >> $REPORT_FILE
              OVERALL_SUCCESS=false
              continue
            fi
            
            # Backup committed results
            echo ""
            echo "Backing up committed results..."
            for TEST_TYPE in positive negative; do
              TEST_PATH="rules/$RULE_ID/$TEST_TYPE"
              if [ -d "$TEST_PATH" ]; then
                for CASE_DIR in "$TEST_PATH"/*; do
                  if [ -d "$CASE_DIR" ] && [ -f "$CASE_DIR/results/results.json" ]; then
                    cp "$CASE_DIR/results/results.json" "$CASE_DIR/results/results.json.committed"
                    echo "  Backed up: $CASE_DIR/results/results.json"
                  fi
                done
              fi
            done
            
            # Generate fresh results
            echo ""
            echo "Generating fresh results..."
            
            $PYTHON_CMD -c "from test import generate_rule_results; generate_rule_results('$RULE_ID')"
            
            if [ $? -ne 0 ]; then
              echo "ERROR: Failed to generate results for $RULE_ID"
              echo "**ERROR:** Failed to generate results" >> $REPORT_FILE
              echo "" >> $REPORT_FILE
              OVERALL_SUCCESS=false
              continue
            fi
            
            # Compare results
            echo ""
            echo "Comparing generated vs committed results..."
            
            RULE_PASSED=true
            CASE_COUNT=0
            PASSED_COUNT=0
            FAILED_COUNT=0
            
            for TEST_TYPE in positive negative; do
              TEST_PATH="rules/$RULE_ID/$TEST_TYPE"
              
              if [ ! -d "$TEST_PATH" ]; then
                continue
              fi
              
              for CASE_DIR in "$TEST_PATH"/*; do
                if [ ! -d "$CASE_DIR" ]; then
                  continue
                fi
                
                CASE_ID=$(basename "$CASE_DIR")
                COMMITTED_RESULTS="$CASE_DIR/results/results.json.committed"
                GENERATED_RESULTS="$CASE_DIR/results/results.json"
                
                CASE_COUNT=$((CASE_COUNT + 1))
                
                if [ ! -f "$COMMITTED_RESULTS" ]; then
                  echo "  $TEST_TYPE/$CASE_ID: No committed results found"
                  echo "\`$TEST_TYPE/$CASE_ID\`: No committed results found" >> $REPORT_FILE
                  continue
                fi
                
                if [ ! -f "$GENERATED_RESULTS" ]; then
                  echo "  $TEST_TYPE/$CASE_ID: Failed to generate results"
                  echo "\`$TEST_TYPE/$CASE_ID\`: Failed to generate results" >> $REPORT_FILE
                  RULE_PASSED=false
                  FAILED_COUNT=$((FAILED_COUNT + 1))
                  continue
                fi
                
                # Create unique temp file for this case
                TEMP_OUTPUT="/tmp/validator_${TEST_TYPE}_${CASE_ID}.txt"
                
                # Run validator and capture output (tee sends to both stdout and file)
                $PYTHON_CMD tests/validator.py "$COMMITTED_RESULTS" "$GENERATED_RESULTS" "$TEST_TYPE" "$CASE_ID" 2>&1 | tee "$TEMP_OUTPUT"
                VALIDATOR_EXIT_CODE=${PIPESTATUS[0]}
                
                if [ $VALIDATOR_EXIT_CODE -ne 0 ]; then
                  echo "\`$TEST_TYPE/$CASE_ID\`: Validation failed" >> $REPORT_FILE
                  RULE_PASSED=false
                  FAILED_COUNT=$((FAILED_COUNT + 1))
                else
                  echo "\`$TEST_TYPE/$CASE_ID\`: Passed" >> $REPORT_FILE
                  PASSED_COUNT=$((PASSED_COUNT + 1))
                fi
                
                # Add validator output details for ALL cases (passed or failed)
                if [ -f "$TEMP_OUTPUT" ] && [ -s "$TEMP_OUTPUT" ]; then
                  echo "<details><summary>View details</summary>" >> $REPORT_FILE
                  echo "" >> $REPORT_FILE
                  echo '```' >> $REPORT_FILE
                  cat "$TEMP_OUTPUT" >> $REPORT_FILE
                  echo '```' >> $REPORT_FILE
                  echo "</details>" >> $REPORT_FILE
                fi
                echo "" >> $REPORT_FILE
              done
            done
            
            echo "" >> $REPORT_FILE
            echo "**Summary:** $PASSED_COUNT passed, $FAILED_COUNT failed (Total: $CASE_COUNT test cases)" >> $REPORT_FILE
            echo "" >> $REPORT_FILE
            
            if [ "$RULE_PASSED" = false ]; then
              echo "Validation failed for $RULE_ID"
              OVERALL_SUCCESS=false
            else
              echo "All validations passed for $RULE_ID"
            fi
          done
          
          # Exit with appropriate code
          if [ "$OVERALL_SUCCESS" = false ]; then
            exit 1
          fi

      - name: Post validation report
        if: always() && steps.changed-rules.outputs.rules != ''
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const reportPath = 'validation_report.md';
            
            let reportBody = '## Rule Validation Results\n\n';
            reportBody += 'No validation report generated.';
            
            if (fs.existsSync(reportPath)) {
              reportBody = fs.readFileSync(reportPath, 'utf8');
            }
            
            // Add workflow run link
            reportBody += '\n\n---\n';
            reportBody += `[View workflow run](${context.payload.repository.html_url}/actions/runs/${context.runId})`;
            
            // Find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const botComment = comments.find(comment => 
              comment.user.type === 'Bot' && 
              comment.body.includes('Rule Validation Results')
            );
            
            // Create or update comment
            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: reportBody
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: reportBody
              });
            }

      - name: Check validation status
        if: steps.validate.outcome == 'failure'
        run: |
          echo "Validation failed - see report in PR comments"
          exit 1